# data-course-sample

## Week 1
專案目標:
推薦平均評分高且評論數達到一定門檻的商品

推薦結果: 成功

推薦分數: 0.0067

推薦方法:
1. 訓練資料groupby "asin"欄位，計算"overall"欄位的mean & size
2. 自訂一個size門檻為100，用來過濾頻論數太低的商品，因為過低的評論數容易有主觀上的誤差 (這裡的100是隨意定的，沒有特定計算方式)
3. 將篩選過後的資料以"mean"欄位由高到低做排序
4. 選取top-N結果
5. 將top-N結果推薦給使用者前先做一次隨機排列，讓每個使用者可以看到不同結果，避免曝光過度集中在某些商品上

## Week 2
使用description欄位資料進行相似度計算，根據使用者過去購買過商品進行類似商品的推薦，若使用者過去沒有買過商品，則使用最常被購買的商品做替代

最終推薦分數:0.08 

## Week 3
### User-based from scratch
方法: 
- 想要驗證轉置方法是否真的能優化運算效率，因此使用依照user維度計算相似度的方法
- 針對無法透過CF進行推薦的users，使用rule-based推薦評論數最多的商品

Finding:
- 不使用轉置方法的話，運算時間確實多了非常多，將近1小時
- 然而使用轉置是因為原始資料中user之間對於同一商品都有評價的比例極低
- 實務上，是使用轉置方法屬於常態？又或是對於此資料應該判定不適用於CF方法？

推薦分數: 0.08

### Item-based from scratch
方法:
- 原範例中將user已經買過的商品排除在推薦清單外，即使如此成效依然沒有變好，這次嘗試將已買過的商品也加入推薦，理由是買過商品也有回購可能
- 由於已知無論是user/item based，資料交集度都非常差，因此在評估成效時僅使用有透過CF方法推薦的users做評估

Finding:
- 雖然將範圍限縮在只針對CF推薦的結果作評估，但結果一樣不理想
- 推測反而是因為限縮了資料量體，又或是這份資料本身的構成就不適合CF方法

推薦分數: 0

### CF using Surprise lib
方法:
- 過濾購買不足3次的users
- 原訓練資料太過龐大，直接訓練會造成記憶體不足，且在手刻CF練習中，曾做過一樣的資料過濾來縮小資料量
- 所以這裡也同樣過濾掉購買不足3的users來做比較

Finding:
- 限縮資料量之後，在Google Colab環境下雖可正常執行，然而結果也比範例的分數還低
- 我認為這個結果符合Item-based from scratch 的推測，因為原本資料交集度就很差，限縮資料之後只會得到更差的結果
- 因此或許在條件允許的狀況下，應盡量滿足運算所需效能，而不是捨棄原始資料

推薦分數: 0
